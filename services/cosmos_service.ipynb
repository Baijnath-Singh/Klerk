{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"c:\\\\Users\\\\baisingh\\\\go\\\\src\\\\Klerk\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pymongo\n",
    "import requests\n",
    "from pymongo import UpdateOne, DeleteMany\n",
    "from dotenv import load_dotenv\n",
    "from models.karnatakaLegalBook import KarnatakaLegalBook, KarnatakaLegalBookList\n",
    "from datetime import datetime, timezone\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "CONNECTION_STRING = os.environ.get(\"DB_CONNECTION_STRING\")\n",
    "EMBEDDINGS_DEPLOYMENT_NAME = os.environ.get(\"OPENAI_LLM_EMBEDDING\")\n",
    "AOAI_ENDPOINT = os.environ.get(\"OPENAI_API_ENDPOINT\")\n",
    "AOAI_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "AOAI_API_VERSION = \"2023-05-15\"\n",
    "client = pymongo.MongoClient(CONNECTION_STRING)\n",
    "print(CONNECTION_STRING)\n",
    "# Create database to hold cosmic works data\n",
    "# MongoDB will create the database \"karnatakaLegalBook\" if it does not exist\n",
    "db = client.karnatakaLegalBook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add document registration data to database using bulkwrite and updateOne with upsert\n",
    "# Get karnataka klerk document registration data from github\n",
    "from bson.json_util import loads\n",
    "# Corrected URL for raw JSON data\n",
    "kr_legal_raw_data = \"https://raw.githubusercontent.com/Baijnath-Singh/Klerk/main/models/karnatakaLegalBook.json\"\n",
    "\n",
    "# Fetch the raw JSON data\n",
    "response = requests.get(kr_legal_raw_data)\n",
    "response.raise_for_status()  # Ensure we raise an error for bad status codes\n",
    "\n",
    "# Parse the JSON data\n",
    "data = response.json()\n",
    "\n",
    "# Create KnowledgeDocumentList from the parsed JSON data\n",
    "kr_legal_data = KarnatakaLegalBookList(items=[KarnatakaLegalBook(**item) for item in data])\n",
    "\n",
    "# Perform bulk write to MongoDB\n",
    "db.document_registration.bulk_write([\n",
    "    UpdateOne({\"_id\": dr.id}, {\"$set\": loads(dr.json(by_alias=True))}, upsert=True)\n",
    "    for dr in kr_legal_data.items\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Read and print documents from the collection\n",
    "documents = db.document_registration.find().limit(10)  # Limiting to 10 documents for brevity\n",
    "count = 0\n",
    "for doc in documents:\n",
    "    count = count + 1\n",
    "    print(json.dumps(doc, indent=4, default=str))  # Convert ObjectId to string for printing\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "ai_client = AzureOpenAI(\n",
    "    azure_endpoint = AOAI_ENDPOINT,\n",
    "    api_version = AOAI_API_VERSION,\n",
    "    api_key = AOAI_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(3))\n",
    "def generate_embeddings(text: str):\n",
    "    '''\n",
    "    Generate embeddings from string of text using the deployed Azure OpenAI API embeddings model.\n",
    "    This will be used to vectorize document data and incoming user messages for a similarity search with\n",
    "    the vector index.\n",
    "    '''\n",
    "    response = ai_client.embeddings.create(input=text, model=EMBEDDINGS_DEPLOYMENT_NAME)\n",
    "    embeddings = response.data[0].embedding\n",
    "    time.sleep(0.1) # rest period to avoid rate limiting on AOAI\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate embeddings generation using a test string\n",
    "test = \"hello, world\"\n",
    "print(generate_embeddings(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_collection_content_vector_field(collection_name: str):\n",
    "    '''\n",
    "    Add a new field to the collection to hold the vectorized content of each document.\n",
    "    '''\n",
    "    collection = db[collection_name]\n",
    "    bulk_operations = []\n",
    "    for doc in collection.find():\n",
    "        # remove any previous contentVector embeddings\n",
    "        if \"contentVector\" in doc:\n",
    "            del doc[\"contentVector\"]\n",
    "\n",
    "        # generate embeddings for the document string representation\n",
    "        content = json.dumps(doc, default=str)\n",
    "        content_vector = generate_embeddings(content)       \n",
    "        \n",
    "        bulk_operations.append(pymongo.UpdateOne(\n",
    "            {\"_id\": doc[\"_id\"]},\n",
    "            {\"$set\": {\"contentVector\": content_vector}},\n",
    "            upsert=True\n",
    "        ))\n",
    "    # execute bulk operations\n",
    "    collection.bulk_write(bulk_operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add vector field to products documents - this will take approximately 3-5 minutes due to rate limiting\n",
    "add_collection_content_vector_field(\"document_registration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the document registration vector index\n",
    "db.command({\n",
    "  'createIndexes': 'document_registration',  # Name of the collection where the index is to be created\n",
    "  'indexes': [\n",
    "    {\n",
    "      'name': 'VectorSearchIndex',  # Name of the index\n",
    "      'key': {\n",
    "        \"contentVector\": \"cosmosSearch\"  # Field to be indexed, using a special \"cosmosSearch\" type for vector search\n",
    "      },\n",
    "      'cosmosSearchOptions': {\n",
    "        'kind': 'vector-ivf',  # Type of vector index, IVF (Inverted File) in this case\n",
    "        'numLists': 1,  # Number of inverted lists used in the IVF index\n",
    "        'similarity': 'COS',  # Similarity metric, COS stands for Cosine Similarity\n",
    "        'dimensions': 1536  # Dimensionality of the vectors being indexed\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(collection_name, query, num_results=3):\n",
    "    \"\"\"\n",
    "    Perform a vector search on the specified collection by vectorizing\n",
    "    the query and searching the vector index for the most similar documents.\n",
    "\n",
    "    returns a list of the top num_results most similar documents\n",
    "    \"\"\"\n",
    "    collection = db[collection_name]\n",
    "    query_embedding = generate_embeddings(query)    \n",
    "    pipeline = [\n",
    "        {\n",
    "            '$search': {\n",
    "                \"cosmosSearch\": {\n",
    "                    \"vector\": query_embedding,\n",
    "                    \"path\": \"contentVector\",\n",
    "                    \"k\": num_results\n",
    "                },\n",
    "                \"returnStoredSource\": True }},\n",
    "        {'$project': { 'similarityScore': { '$meta': 'searchScore' }, 'document' : '$$ROOT' } }\n",
    "    ]\n",
    "    results = collection.aggregate(pipeline)\n",
    "    return results\n",
    "\n",
    "def print_product_search_result(result):\n",
    "    '''\n",
    "    Print the search result document in a readable format\n",
    "    '''\n",
    "    print(f\"Similarity Score: {result['similarityScore']}\")  \n",
    "    print(f\"Category: {result['document']['category']}\")   \n",
    "    print(f\"Question: {result['document']['question']}\")\n",
    "    print(f\"Answer: {result['document']['answer']}\")\n",
    "    print(f\"_id: {result['document']['_id']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How ownership of immovable property is acquired by a person?\"\n",
    "results = vector_search(\"document_registration\", query, num_results=1)\n",
    "for result in results:\n",
    "    print_product_search_result(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.drop_collection(\"document_registration\")\n",
    "client.drop_database(\"karnataka_klerk\")\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
